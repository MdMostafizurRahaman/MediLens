{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import time\n",
        "from pathlib import Path\n",
        "import logging\n",
        "import json\n",
        "import sys\n",
        "import traceback\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Configure API with environment variable\n",
        "API_KEY = os.getenv('GEMINI_API_KEY')\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"GEMINI_API_KEY not found in environment variables\")\n",
        "\n",
        "genai.configure(api_key=API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_and_truncate_example(example, max_length=5000):\n",
        "    \"\"\"Validate and truncate training example to meet API requirements.\"\"\"\n",
        "    truncated = example.copy()\n",
        "    if len(truncated['text_output']) > max_length:\n",
        "        truncated['text_output'] = truncated['text_output'][:max_length-3] + \"...\"\n",
        "    return truncated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_training_data(data_path: str, max_examples_per_epoch=12500) -> tuple:\n",
        "    \"\"\"Prepare medical terminology data for fine-tuning with size limits.\n",
        "    Returns tuple of (training_data, recommended_epochs)\n",
        "    \"\"\"\n",
        "    if not Path(data_path).exists():\n",
        "        raise FileNotFoundError(f\"Training data not found at {data_path}\")\n",
        "\n",
        "    # Check if data is JSON or CSV\n",
        "    if data_path.endswith('.json'):\n",
        "        # Load JSON training data (already processed)\n",
        "        with open(data_path, 'r', encoding='utf-8') as f:\n",
        "            training_examples = json.load(f)\n",
        "\n",
        "        logging.info(f\"Loaded {len(training_examples)} pre-processed training examples from JSON\")\n",
        "\n",
        "    else:\n",
        "        # Load CSV data and process it\n",
        "        df = pd.read_csv(data_path)\n",
        "        required_columns = ['Term', 'Explanation', 'Category']\n",
        "        if not all(col in df.columns for col in required_columns):\n",
        "            raise ValueError(f\"Training data must contain columns: {required_columns}\")\n",
        "\n",
        "        training_examples = []\n",
        "        for _, row in df.iterrows():\n",
        "            examples = [\n",
        "                {\n",
        "                    \"text_input\": f\"Define the medical term: {row['Term']}\",\n",
        "                    \"text_output\": f\"{row['Explanation']} (Category: {row['Category']})\"\n",
        "                },\n",
        "                {\n",
        "                    \"text_input\": f\"What category is the medical term '{row['Term']}' in?\",\n",
        "                    \"text_output\": row['Category']\n",
        "                },\n",
        "                {\n",
        "                    \"text_input\": f\"What medical term matches this description: {row['Explanation']}\",\n",
        "                    \"text_output\": row['Term']\n",
        "                }\n",
        "            ]\n",
        "\n",
        "            # Validate and truncate each example\n",
        "            training_examples.extend([\n",
        "                validate_and_truncate_example(ex) for ex in examples\n",
        "            ])\n",
        "\n",
        "        # Save processed data as JSON for future use\n",
        "        output_path = Path(data_path).parent / \"training_data.json\"\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(training_examples, f, indent=2)\n",
        "        logging.info(f\"Saved processed data to {output_path}\")\n",
        "\n",
        "    # Calculate recommended epochs to stay under 250,000 total examples\n",
        "    total_examples = len(training_examples)\n",
        "    recommended_epochs = min(20, 250000 // total_examples)\n",
        "\n",
        "    # If we have too many examples even for 1 epoch, subsample\n",
        "    if total_examples > max_examples_per_epoch:\n",
        "        logging.warning(f\"Subsampling training data from {total_examples} to {max_examples_per_epoch} examples\")\n",
        "        import random\n",
        "        random.seed(42)  # For reproducibility\n",
        "        training_examples = random.sample(training_examples, max_examples_per_epoch)\n",
        "\n",
        "    logging.info(f\"Final training data: {len(training_examples)} examples\")\n",
        "    logging.info(f\"Recommended epochs: {recommended_epochs}\")\n",
        "    logging.info(f\"Sample training example: {training_examples[0]}\")\n",
        "\n",
        "    return training_examples, recommended_epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fine_tune_model(\n",
        "    training_data_path: str,\n",
        "    base_model: str = \"models/gemini-1.5-flash-001-tuning\",\n",
        "    model_name: str = \"medical-terms-model\",\n",
        "    batch_size: int = 4,\n",
        "    learning_rate: float = 0.001,\n",
        "    wait_interval: int = 10\n",
        ") -> tuple:\n",
        "    \"\"\"Fine-tune a Gemini model for medical terminology with automatic epoch calculation\"\"\"\n",
        "    try:\n",
        "        # Prepare and validate training data\n",
        "        training_data, recommended_epochs = prepare_training_data(training_data_path)\n",
        "\n",
        "        logging.info(f\"Starting fine-tuning process for medical terminology model\")\n",
        "        logging.info(f\"Using base model: {base_model}\")\n",
        "        logging.info(f\"Using {recommended_epochs} epochs based on data size\")\n",
        "\n",
        "        # Create fine-tuning operation\n",
        "        operation = genai.create_tuned_model(\n",
        "            display_name=model_name,\n",
        "            source_model=base_model,\n",
        "            epoch_count=recommended_epochs,\n",
        "            batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            training_data=training_data,\n",
        "            input_key=\"text_input\",\n",
        "            output_key=\"text_output\"\n",
        "        )\n",
        "\n",
        "        # Monitor training progress\n",
        "        logging.info(\"Training started...\")\n",
        "        snapshots = []\n",
        "        for status in operation.wait_bar():\n",
        "            logging.info(f\"Training status: {status}\")\n",
        "            snapshots.append(status)\n",
        "            time.sleep(wait_interval)\n",
        "\n",
        "        result = operation.result()\n",
        "        model = genai.GenerativeModel(model_name=result.name)\n",
        "\n",
        "        # Save training metrics\n",
        "        metrics = pd.DataFrame(result.tuning_task.snapshots)\n",
        "        metrics.to_csv('training_metrics.csv', index=False)\n",
        "\n",
        "        logging.info(f\"Training completed successfully. Model name: {result.name}\")\n",
        "        return model, metrics\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error during fine-tuning: {str(e)}\")\n",
        "        logging.error(f\"Stack trace: {traceback.format_exc()}\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model, test_terms: list):\n",
        "    \"\"\"Test the fine-tuned model with some example queries\"\"\"\n",
        "    for term in test_terms:\n",
        "        try:\n",
        "            # Test definition query\n",
        "            response = model.generate_content(f\"Define the medical term: {term}\")\n",
        "            print(f\"Term: {term}\")\n",
        "            print(f\"Definition: {response.text}\")\n",
        "\n",
        "            # Test category query\n",
        "            response = model.generate_content(f\"What category is the medical term '{term}' in?\")\n",
        "            print(f\"Category: {response.text}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error testing term {term}: {str(e)}\")\n",
        "            logging.error(f\"Stack trace: {traceback.format_exc()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Setup logging with more detailed format\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(levelname)s - %(module)s - %(message)s'\n",
        "    )\n",
        "\n",
        "    # Configuration from environment variables\n",
        "    TRAINING_DATA = os.getenv('TRAINING_DATA_PATH', './training_data.json')\n",
        "    BASE_MODEL = os.getenv('BASE_MODEL', 'models/gemini-1.5-flash-001-tuning')\n",
        "    MODEL_NAME = os.getenv('MODEL_NAME', 'medical-terminology-assistant')\n",
        "    BATCH_SIZE = int(os.getenv('BATCH_SIZE', '4'))\n",
        "\n",
        "    try:\n",
        "        # Fine-tune model\n",
        "        model, metrics = fine_tune_model(\n",
        "            training_data_path=TRAINING_DATA,\n",
        "            base_model=BASE_MODEL,\n",
        "            model_name=MODEL_NAME,\n",
        "            batch_size=BATCH_SIZE\n",
        "        )\n",
        "\n",
        "        # Test the model with some example terms\n",
        "        test_terms = [\"ADHD\", \"ACE\", \"ABO system\"]\n",
        "        test_model(model, test_terms)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Training failed: {str(e)}\")\n",
        "        logging.error(f\"Stack trace: {traceback.format_exc()}\")\n",
        "        sys.exit(1)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
