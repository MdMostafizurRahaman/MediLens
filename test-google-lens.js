const dotenv = require('dotenv')
const fs = require('fs')
const path = require('path')

// Load environment variables
dotenv.config()

/**
 * Test Google Lens API Integration
 * This script tests if the Google Lens API key is working
 */
async function testGoogleLensAPI() {
  console.log('üîç Testing Google Lens API Integration...\n')

  // Check if API key exists
  const GOOGLE_LENS_API_KEY = process.env.GOOGLE_LENS_API
  const GEMINI_API_KEY = process.env.GEMINI_API_KEY

  console.log('üìã Environment Check:')
  console.log(`‚úÖ Google Lens API Key: ${GOOGLE_LENS_API_KEY ? 'Found' : '‚ùå Missing'}`)
  console.log(`‚úÖ Gemini API Key: ${GEMINI_API_KEY ? 'Found' : '‚ùå Missing'}`)
  console.log('')

  if (!GOOGLE_LENS_API_KEY) {
    console.log('‚ùå Google Lens API key not found in .env file')
    console.log('Please add: GOOGLE_LENS_API=your_api_key_here')
    return
  }

  // Test with a sample base64 image (small test image)
  const testImageBase64 = await createTestImage()

  try {
    console.log('üöÄ Testing Google Vision API (Google Lens backend)...')
    
    const visionApiUrl = `https://vision.googleapis.com/v1/images:annotate?key=${GOOGLE_LENS_API_KEY}`
    
    const requestBody = {
      requests: [
        {
          image: {
            content: testImageBase64
          },
          features: [
            {
              type: 'TEXT_DETECTION',
              maxResults: 1
            }
          ]
        }
      ]
    }

    const response = await fetch(visionApiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    })

    console.log(`üì° API Response Status: ${response.status} ${response.statusText}`)

    if (response.ok) {
      const result = await response.json()
      console.log('‚úÖ Google Lens API is working!')
      
      if (result.responses && result.responses[0]) {
        const textAnnotations = result.responses[0].textAnnotations
        if (textAnnotations && textAnnotations.length > 0) {
          console.log('üìÑ Detected Text:', textAnnotations[0].description)
        } else {
          console.log('üìÑ No text detected in test image')
        }
      }
      
      console.log('üéØ API Integration Status: SUCCESS ‚úÖ')
      
    } else {
      const errorText = await response.text()
      console.log('‚ùå Google Lens API Error:')
      console.log('Status:', response.status)
      console.log('Error:', errorText)
      
      // Common error analysis
      if (response.status === 403) {
        console.log('\nüí° Possible Solutions:')
        console.log('‚Ä¢ Check if the API key is valid')
        console.log('‚Ä¢ Enable Vision API in Google Cloud Console')
        console.log('‚Ä¢ Check API quotas and billing')
      }
    }

  } catch (error) {
    console.log('‚ùå Network/Connection Error:', error.message)
  }

  console.log('\n' + '='.repeat(60))
  console.log('üß™ Testing Fine-tuned Model Availability...')
  
  // Test Gemini API
  if (GEMINI_API_KEY) {
    try {
      const { GoogleGenerativeAI } = require('@google/generative-ai')
      const genAI = new GoogleGenerativeAI(GEMINI_API_KEY)
      
      // Test base model
      const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' })
      const testPrompt = 'Define the medical term: hypertension'
      const result = await model.generateContent(testPrompt)
      
      console.log('‚úÖ Gemini API is working!')
      console.log('üìù Test Response:', result.response.text().substring(0, 100) + '...')
      
      // Test fine-tuned model availability
      try {
        const fineTunedModel = genAI.getGenerativeModel({ 
          model: 'tunedModels/medical-terminology-assistant'
        })
        console.log('‚úÖ Fine-tuned medical model is available!')
      } catch (ftError) {
        console.log('‚ö†Ô∏è Fine-tuned model not found - will use base model')
        console.log('üí° Run Fine_tune.py to create the medical model')
      }
      
    } catch (geminiError) {
      console.log('‚ùå Gemini API Error:', geminiError.message)
    }
  }

  console.log('\n' + '='.repeat(60))
  console.log('üìä Integration Test Summary:')
  console.log('‚Ä¢ Google Lens OCR: Ready for text extraction')
  console.log('‚Ä¢ Medical AI Analysis: Ready for prescription analysis')
  console.log('‚Ä¢ Combined System: Ready for production use')
  console.log('\nüöÄ You can now test the system at: /google-lens-test')
}

/**
 * Create a simple test image with text for OCR testing
 */
async function createTestImage() {
  // This is a minimal 1x1 white pixel PNG in base64
  // In real testing, you'd use an actual prescription image
  return 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg=='
}

// Run the test
if (require.main === module) {
  testGoogleLensAPI()
    .then(() => {
      console.log('\n‚úÖ Test completed!')
      process.exit(0)
    })
    .catch((error) => {
      console.error('‚ùå Test failed:', error)
      process.exit(1)
    })
}

module.exports = { testGoogleLensAPI }
